//! Markdown report generation for benchmark results.
//!
//! This module generates human-readable markdown summaries of benchmark results.

use crate::BenchmarkResult;
use chrono::Utc;

/// Generates a markdown summary from benchmark results.
pub fn generate_summary(results: &[BenchmarkResult]) -> String {
    let mut md = String::new();

    // Header
    md.push_str("# Benchmark Results Summary\n\n");
    md.push_str(&format!(
        "Generated: {}\n\n",
        Utc::now().format("%Y-%m-%d %H:%M:%S UTC")
    ));

    // Overview table
    md.push_str("## Overview\n\n");
    md.push_str("| Target | Key Metric | Value | Timestamp |\n");
    md.push_str("|--------|------------|-------|----------|\n");

    for result in results {
        let key_metric = extract_key_metric(&result.metrics);
        md.push_str(&format!(
            "| {} | {} | {} | {} |\n",
            result.target_id,
            key_metric.0,
            key_metric.1,
            result.timestamp.format("%H:%M:%S")
        ));
    }

    md.push('\n');

    // Detailed results
    md.push_str("## Detailed Results\n\n");

    for result in results {
        md.push_str(&format!("### {}\n\n", result.target_id));
        md.push_str(&format!(
            "**Executed:** {}\n\n",
            result.timestamp.format("%Y-%m-%d %H:%M:%S UTC")
        ));

        if let Some(obj) = result.metrics.as_object() {
            md.push_str("| Metric | Value |\n");
            md.push_str("|--------|-------|\n");

            for (key, value) in obj {
                md.push_str(&format!(
                    "| {} | {} |\n",
                    format_metric_name(key),
                    format_metric_value(value)
                ));
            }
        }

        md.push('\n');
    }

    // Performance summary
    md.push_str("## Performance Summary\n\n");

    if let Some(stats) = calculate_stats(results) {
        md.push_str(&format!("- **Total Benchmarks:** {}\n", results.len()));
        md.push_str(&format!("- **Average Duration:** {:.2} ms\n", stats.avg_duration_ms));
        md.push_str(&format!("- **Total Data Processed:** {} bytes\n", format_bytes(stats.total_data_bytes)));
        if stats.avg_throughput_bps > 0.0 {
            md.push_str(&format!(
                "- **Average Throughput:** {}/s\n",
                format_bytes(stats.avg_throughput_bps as u64)
            ));
        }
    }

    md.push('\n');

    // Footer
    md.push_str("---\n\n");
    md.push_str("*Generated by LLM Data Vault Benchmark Suite*\n");

    md
}

/// Extracts the most important metric from results.
fn extract_key_metric(metrics: &serde_json::Value) -> (String, String) {
    if let Some(obj) = metrics.as_object() {
        // Priority order for key metrics
        let priority = [
            "throughput_bps",
            "ops_per_second",
            "duration_ms",
            "latency_p50_ms",
            "data_size_bytes",
        ];

        for key in priority {
            if let Some(value) = obj.get(key) {
                return (format_metric_name(key), format_metric_value(value));
            }
        }

        // Return first metric if no priority match
        if let Some((key, value)) = obj.iter().next() {
            return (format_metric_name(key), format_metric_value(value));
        }
    }

    ("N/A".to_string(), "N/A".to_string())
}

/// Formats a metric name for display.
fn format_metric_name(name: &str) -> String {
    name.split('_')
        .map(|word| {
            let mut chars = word.chars();
            match chars.next() {
                None => String::new(),
                Some(first) => first.to_uppercase().chain(chars).collect(),
            }
        })
        .collect::<Vec<_>>()
        .join(" ")
}

/// Formats a metric value for display.
fn format_metric_value(value: &serde_json::Value) -> String {
    match value {
        serde_json::Value::Number(n) => {
            if let Some(f) = n.as_f64() {
                if f >= 1_000_000_000.0 {
                    format!("{:.2} B", f / 1_000_000_000.0)
                } else if f >= 1_000_000.0 {
                    format!("{:.2} M", f / 1_000_000.0)
                } else if f >= 1_000.0 {
                    format!("{:.2} K", f / 1_000.0)
                } else if f < 0.01 && f > 0.0 {
                    format!("{:.4}", f)
                } else {
                    format!("{:.2}", f)
                }
            } else {
                n.to_string()
            }
        }
        serde_json::Value::String(s) => s.clone(),
        serde_json::Value::Bool(b) => if *b { "Yes" } else { "No" }.to_string(),
        serde_json::Value::Null => "N/A".to_string(),
        _ => value.to_string(),
    }
}

/// Formats bytes for human-readable display.
fn format_bytes(bytes: u64) -> String {
    const KB: u64 = 1024;
    const MB: u64 = KB * 1024;
    const GB: u64 = MB * 1024;

    if bytes >= GB {
        format!("{:.2} GB", bytes as f64 / GB as f64)
    } else if bytes >= MB {
        format!("{:.2} MB", bytes as f64 / MB as f64)
    } else if bytes >= KB {
        format!("{:.2} KB", bytes as f64 / KB as f64)
    } else {
        format!("{} B", bytes)
    }
}

/// Statistics calculated from benchmark results.
struct BenchmarkStats {
    avg_duration_ms: f64,
    total_data_bytes: u64,
    avg_throughput_bps: f64,
}

/// Calculates aggregate statistics from results.
fn calculate_stats(results: &[BenchmarkResult]) -> Option<BenchmarkStats> {
    if results.is_empty() {
        return None;
    }

    let mut total_duration = 0.0;
    let mut duration_count = 0;
    let mut total_data: u64 = 0;
    let mut total_throughput = 0.0;
    let mut throughput_count = 0;

    for result in results {
        if let Some(obj) = result.metrics.as_object() {
            if let Some(duration) = obj.get("duration_ms").and_then(|v| v.as_f64()) {
                total_duration += duration;
                duration_count += 1;
            }

            if let Some(data_size) = obj.get("data_size_bytes").and_then(|v| v.as_u64()) {
                total_data += data_size;
            }

            if let Some(throughput) = obj.get("throughput_bps").and_then(|v| v.as_f64()) {
                total_throughput += throughput;
                throughput_count += 1;
            }
        }
    }

    Some(BenchmarkStats {
        avg_duration_ms: if duration_count > 0 {
            total_duration / duration_count as f64
        } else {
            0.0
        },
        total_data_bytes: total_data,
        avg_throughput_bps: if throughput_count > 0 {
            total_throughput / throughput_count as f64
        } else {
            0.0
        },
    })
}

/// Generates a comparison table between two benchmark runs.
pub fn generate_comparison(
    baseline: &[BenchmarkResult],
    current: &[BenchmarkResult],
) -> String {
    let mut md = String::new();

    md.push_str("# Benchmark Comparison\n\n");
    md.push_str("| Target | Metric | Baseline | Current | Change |\n");
    md.push_str("|--------|--------|----------|---------|--------|\n");

    for current_result in current {
        if let Some(baseline_result) = baseline
            .iter()
            .find(|b| b.target_id == current_result.target_id)
        {
            if let (Some(base_obj), Some(curr_obj)) = (
                baseline_result.metrics.as_object(),
                current_result.metrics.as_object(),
            ) {
                for (key, curr_val) in curr_obj {
                    if let (Some(base_f), Some(curr_f)) =
                        (base_obj.get(key).and_then(|v| v.as_f64()), curr_val.as_f64())
                    {
                        let change = if base_f != 0.0 {
                            ((curr_f - base_f) / base_f) * 100.0
                        } else {
                            0.0
                        };

                        let change_str = if change > 0.0 {
                            format!("+{:.1}%", change)
                        } else {
                            format!("{:.1}%", change)
                        };

                        md.push_str(&format!(
                            "| {} | {} | {} | {} | {} |\n",
                            current_result.target_id,
                            format_metric_name(key),
                            format_metric_value(&serde_json::json!(base_f)),
                            format_metric_value(curr_val),
                            change_str
                        ));
                    }
                }
            }
        }
    }

    md
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_generate_summary() {
        let results = vec![
            BenchmarkResult::new(
                "encryption-benchmark",
                serde_json::json!({
                    "duration_ms": 150.5,
                    "throughput_bps": 1_000_000.0,
                    "data_size_bytes": 1024
                }),
            ),
            BenchmarkResult::new(
                "hashing-benchmark",
                serde_json::json!({
                    "duration_ms": 50.0,
                    "ops_per_second": 10000.0
                }),
            ),
        ];

        let summary = generate_summary(&results);

        assert!(summary.contains("# Benchmark Results Summary"));
        assert!(summary.contains("encryption-benchmark"));
        assert!(summary.contains("hashing-benchmark"));
        assert!(summary.contains("## Detailed Results"));
    }

    #[test]
    fn test_format_metric_name() {
        assert_eq!(format_metric_name("duration_ms"), "Duration Ms");
        assert_eq!(format_metric_name("ops_per_second"), "Ops Per Second");
    }

    #[test]
    fn test_format_bytes() {
        assert_eq!(format_bytes(500), "500 B");
        assert_eq!(format_bytes(2048), "2.00 KB");
        assert_eq!(format_bytes(5 * 1024 * 1024), "5.00 MB");
    }
}
